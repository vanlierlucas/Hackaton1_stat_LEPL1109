{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2de761",
   "metadata": {},
   "source": [
    "# Hackathon 1, statistics.\n",
    "\n",
    "This project illustrates the statistics part of the course LEPL1109. In the first part of the project, you will study the China water pollution by analyzing a dataset providing the water pollution levels collected from various monitoring stations across 10 major provinces in China throughout the year 2023. In the second part of the project, you will analyze a dataset containing high-frequency time-series  data collected from an industrial boiler operating in a chemical plant.\n",
    "\n",
    "## Report content\n",
    "\n",
    "•\tGrades are granted to the members whose names are in the Jupyter notebook. If your name doesn’t appear on the top of the notebook, you’ll get a 0, even though you are in a group on Moodle.\n",
    "\n",
    "•\tThe jupyter notebook must be compiled with printed results and next submitted via moodle. The absence of compiled results (or non-printed values) leads to a lower grade.\n",
    "\n",
    "•\tDo not comment your results directly into cells of code. Use instead a Markdown cell. \n",
    "\n",
    "•\t\"Dry\" code or results not followed by a minimum of analysis / comments will be penalized.\n",
    "\n",
    "\n",
    "## Report submission\n",
    "\n",
    "•\tDeadline, see moodle website. Submission after the deadline will not be accepted.\n",
    "\n",
    "•\tTo submit your report, go to the section “APP” on Moodle and the subsection “Soumission du rapport”. You can upload your work there. Once you are sure that it is your final version, click the button “Envoyer le devoir”. It is important that you don’t forget to click on this button ! \n",
    "\n",
    "•\tReports that have not been uploaded through Moodle will not be corrected.\n",
    "\n",
    "\n",
    "## Names and Noma of participants:\n",
    "\n",
    "Part. 1: \n",
    "\n",
    "Part. 2:\n",
    "\n",
    "Part. 3:\n",
    "\n",
    "Part. 4:\n",
    "\n",
    "Part. 5:\n",
    "\n",
    "Part. 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dca778",
   "metadata": {},
   "source": [
    "# China Water Pollution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b54a9",
   "metadata": {},
   "source": [
    "This dataset provides  water pollution levels collected from various monitoring stations across 10 major provinces in China throughout the year 2023. The data  includes  parameters such as pH, turbidity, chemical and biological oxygen demand, nutrient levels, and heavy metal concentrations. These indicators are widely used by environmental monitoring agencies to assess water quality for ecological, human, and industrial impacts.\n",
    "\n",
    "We will focus on the Water Quality Index. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16105d88",
   "metadata": {},
   "source": [
    "## 1. Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c2a3e",
   "metadata": {},
   "source": [
    "1.a) Load the dataset 'china_water_pollution_data_hack.csv'. Convert Province, City  to categorical variables. (**0.5 pt**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a899ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4b40e",
   "metadata": {},
   "source": [
    "1.b) Calculate the mean, variance, median, 25% and 75% quantiles of the water quality index (which ranges from 0 to 100) for all cities in the dataset. Comment your results! (**1.5 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23b501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3aabd4",
   "metadata": {},
   "source": [
    "Comment here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed64230",
   "metadata": {},
   "source": [
    "## 2. Hypothesis tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c37cf2",
   "metadata": {},
   "source": [
    "2.a) Check with a Student's T test that the average water quality index is the same in Shenzhen and Dali: $$H_0: \\mu_{Shenzhen} = \\mu_{Dali},$$ \n",
    "$$H_1: \\mu_{Shenzhen} \\neq \\mu_{Dali}.$$ Calculate all statistics and p-value without recourse to other functions than statistical distributions (use course's formula). Use a confidence level of 5%. Take care to comment your conclusions. Are all assumptions required to perform this test sastisfied? Which additional test do you have to do to validate your result? (**2.5 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db05e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925fdfa8",
   "metadata": {},
   "source": [
    "Comment here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2619d5f",
   "metadata": {},
   "source": [
    "2.b) 'Wuhan', 'Luoyang', 'Chengdu', 'Nanjing', 'Dali' seems to have similar (and low) water quality index. Test the assumption: $$H_0:  \\mu_{Wuhan} = \\mu_{Luoyang}= \\mu_{Chengdu} = \\mu_{Nanjing} =\\mu_{Dali}.$$\n",
    "**Hint**: reformulate the problem as a linear regression.\n",
    "\n",
    "(**2 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a0a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9021e5",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4fc68",
   "metadata": {},
   "source": [
    "## 3. Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5f1c4",
   "metadata": {},
   "source": [
    "3.a) Propose a regression model which explains the Water_Quality_Index as a function of other explanatory variables, **for the city of Shanghai**. Split your data set into a training set (80% of the data) that you use for fitting the model and a test set (20% of the data) on which you test the accuracy of the model. \n",
    "\n",
    "* Use the OLS() function of the package statsmodels.api to perform the linear regression. \n",
    "* Comment your results (goodness of fit, R2, F-stat and T-stats of coefficients)\n",
    "* Identify potential non-relevant covariates\n",
    "* Calculate the MAE on the test and training sets. \n",
    "\n",
    "(**3 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5fc7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c045a",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30438007",
   "metadata": {},
   "source": [
    "3.b) Same question as 3.a) but now you use a Gaussian process regression. Use a RBF and Matern kernel and compare MAEs of the 2 models. Which one is the best? (**2 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee36ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7917d",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165dad6",
   "metadata": {},
   "source": [
    "# Boiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e7d33",
   "metadata": {},
   "source": [
    "![furnace_plotL](boiler/furnace_plotL.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294f7b0",
   "metadata": {},
   "source": [
    "This dataset contains high-frequency time-series  data collected (every 5 seconds) from an industrial boiler operating in a chemical plant. The boiler is equipped with multiple sensors capturing parameters such as pressure, temperature, flow rate, and oxygen levels. The dataset reflects a real-world industrial scenario. The boiler outlet steam temperature, ranging typically from 530 °C to 545 °C during stable operation, is used as the key indicator of equipment state. Deviations outside this range represent abnormal operating conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfe6ab",
   "metadata": {},
   "source": [
    "## 4. Poisson Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda09de4",
   "metadata": {},
   "source": [
    "4. During stable operations, the outlet steam temperature is in the interval 530 °C to 545 °C. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cef97",
   "metadata": {},
   "source": [
    "a) Load the dataset 'data_boiler.csv', plot the Boiler outlet steam temperature (variable 'TE_8332A.AV_0') and count the number of times this temperature is outside this normal range. What do you observe? (**1 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf60fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5973db89",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4afbf",
   "metadata": {},
   "source": [
    "b) A Poisson process, denoted by $N_t$ is a counting process. The number of events observed during an interval [0,t] is distributed according to a Poisson law with a parameter $\\lambda \\times t$. Using the method of moment, estimate $\\lambda \\times t$, the frequency of overheating **or** underheating (i.e. when we are outside the interval) per hour.\n",
    "\n",
    "Remark: do not forget that time-series data are collected every 5 seconds.\n",
    "\n",
    "(**1.5 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca44e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d965df3",
   "metadata": {},
   "source": [
    "c) Calculate the probability of observing more ( >= ) than 50 abnormal temperatures on 1h. (**1 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd30bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc022754",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c79f9f",
   "metadata": {},
   "source": [
    "## 5. Fit of distributions and forecasting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b05fb",
   "metadata": {},
   "source": [
    "5. The induced draft fan motor current must in normal condition stay below 30 Amp. A current above 30 Amp may cause damage to the installation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7540a5",
   "metadata": {},
   "source": [
    "a) Fit a Gamma and an exponentiated Weibull distributions to the variable YFJ3_AI.AV_0. Compare histograms and  densities, and choose the most appropriate distribution. Using the most appropriate distribution, determine the probability that over a similar period of time, we observe a peak of induced draft fan motor current above 30 Amp. \n",
    "(**3 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013fff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aaedf0",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ee20a",
   "metadata": {},
   "source": [
    "b) You want to set up a prediction algorithm of over- and under-heating (variable TE_8332A.AV_0). The aim is to anticipate any abnormal deviation to take necessary measures for driving back the temperature in $[530 ; 545]$. For this purpose, you will use the measure at time $ t - lag \\times 5s$ for predicting the steam temperature at time t, where $lag$ is the number of 5-seconds lags. The model to fit is of the form:\n",
    "$$Y_t = \\beta_0 + \\beta_1 X^1_{t-lag}+\\beta_2 X^2_{t-lag}+...+\\beta_n X^n_{t-lag}+\\varepsilon,$$ \n",
    "where $Y$ is the target variable (i.e. TE_8332A.AV_0), $(X^1,...,X^n)$ are all the explanatory variables (i.e. all the variables except TE_8332A.AV_0) and $\\varepsilon \\sim N(0,1).$\n",
    "\n",
    "* Create a dataset such that for each date $t$ (each line), you have the target variable at time $t$ and the explanatory variables at time $t-lag \\times 5s$.\n",
    "* Use the OLS() function of the package statsmodels.api to perform the linear regression. \n",
    "* If an explanatory variable is not significant, remove it from your model.\n",
    "* Test different lags and determine  the maximum number of lags, such that the probabilities that your model detects over- and under-heatings are above 90%\n",
    "\n",
    "(**4 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db29923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2c701",
   "metadata": {},
   "source": [
    "Comment here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1661ce",
   "metadata": {},
   "source": [
    "c)  Compare the probabilities that your model detects over- and under-heatings. (**1 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f523dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b1683",
   "metadata": {},
   "source": [
    "Comment here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e84d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
